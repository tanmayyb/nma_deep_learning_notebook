# W1D2 T1: Linear Deep Learning

Playlist: </br>
https://www.youtube.com/playlist?list=PLkBQOLLbi18N9Wtbf8jkcenO5DGi1eH-F


</br>


## Gradient Descent Algorithm
### Section 1.1: Gradients & Steepest Ascent

gradient points towards steepest ascent

### Section 1.2: Grad


### Section 1.3: Gradients & Steepest Ascent

![image](https://user-images.githubusercontent.com/72982560/178560506-172cdff7-2032-44aa-adf2-c1a68e35c3ba.png)


![21039260f69f01b454e349227d97d9acd3c77](https://user-images.githubusercontent.com/72982560/178570683-16168c93-06cb-4b4e-bba0-31f8e813f662.jpg)


![800px-Grosse2017_FIG3](https://user-images.githubusercontent.com/72982560/178570671-dc00469d-3c3e-4860-b50a-642e88350355.png)



**Helper Functions**
<details>
<summary>Seed Function</summary>
<br>

```    
def set_seed(seed=None, seed_torch=True):
  """
  Function that controls randomness. NumPy and random modules must be imported.

  Args:
    seed : Integer
      A non-negative integer that defines the random state. Default is `None`.
    seed_torch : Boolean
      If `True` sets the random seed for pytorch tensors, so pytorch module
      must be imported. Default is `True`.

  Returns:
    Nothing.
  """
  if seed is None:
    seed = np.random.choice(2 ** 32)
  random.seed(seed)
  np.random.seed(seed)
  if seed_torch:
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
```
</details>
<details>
<summary>Seed Worker</summary>
<br>

```
def seed_worker(worker_id):
  
  worker_seed = torch.initial_seed() % 2**32
  np.random.seed(worker_seed)
  random.seed(worker_seed)
  ```
</details>

</br>
List: </br>

<ul>
  <li> Gradient Descent 
  <li> Effect of Depth </br>
  <li> Representation learning </br>
  <li> Simple Models
</ul>
</br>

Design Specification:

<ol>  
  <li> Objective Function</br>
  <li> Learning Rule</br>
  <li> Initialisation</br>
  <li> Environment
</ol>








