# W1D2T2 Learning Hyperparamaters


## section 1: Deep Linear Neural Nets

> single nonlinear hidden layer (given enough number of neurons and infinite training samples) has the potential to approximate any function
<p>
shallow nonlinear neural networks hardly meet their true potential in practice. In the contrast, deep neural nets are often surprisingly powerful in learning complex functions without sacrificing generalization. A core intuition behind deep learning is that deep nets derive their power through learning internal representations.</p>

[ref: A mathematical theory of semantic development in deep neural networks](https://www.pnas.org/doi/10.1073/pnas.1820226116)



> "We use a toy model that represents an "Exactly Heirarchical Model"

![s1_heirarchy](https://user-images.githubusercontent.com/72982560/178743943-b054fe52-3999-4853-9ea1-a7c0805b046f.png)



**Learning Semantic Properties**

[ref: Semantic cognition: A parallel distributed processing approach.](https://psycnet.apa.org/record/2004-18753-000)

[ref: Learning and connectionist representations.](https://psycnet.apa.org/record/1993-97600-001)


## section 2: singular value decomposition

> inits affect learning time and also the representations the mdodel  learns

![s1_IMAPACT](https://user-images.githubusercontent.com/72982560/178744048-63314b46-859e-492f-a721-58092fa5ae18.png) </br>
![S1_LOW](https://user-images.githubusercontent.com/72982560/178744050-35184b93-cccc-4e9a-9832-e2ac47e83437.png) </br>
![S1_HIHG](https://user-images.githubusercontent.com/72982560/178744053-4b44f19d-7e0a-4755-b576-7b70344dd44f.png) </br>


<p>
SVD 'untangles'/decouples the dense layers into parallel independent deep chains of neurons.to understanding the nonlinear learning dynamics of a deep LNN

</p>

<img width="325" alt="svd_decouple" src="https://user-images.githubusercontent.com/72982560/178744094-40aec250-b537-4a22-af8a-47eeba763945.png">


[ref: Gilbert Strang teaching SVD](https://www.youtube.com/watch?v=mBcLRGuAFUk&ab_channel=MITOpenCourseWare)

<p> 
Think! (what does this mean)

In EigenValue decomposition, the amount of variance explained by eigenvectors is proportional to the corresponding eigenvalues. What about the SVD? We see that the gradient descent guides the network to first learn the features that carry more information (have higher singular value)!
</p>


<img width="452" alt="svd" src="https://user-images.githubusercontent.com/72982560/178744133-d7931f05-5619-41f7-9c93-50e0e3476eaa.png">

increase in singular values correspond exactly to increases in learning at each bump/drop. and svd values increase one-by-one.

## section 3: representation similarity analysis

Skipped

## section 4: Illusory Correlations

Skipped

## Bonus Video:

Watched till 20:50
</br>
Compositionality used to bypass the curse of dimensionality.

</br>

**What is compositionality**
[ref: Compositionality in Language](https://iep.utm.edu/compositionality-in-language/#:~:text=Compositionality%20is%20a%20concept%20in,meanings%20of%20E's%20simple%20parts.)

</br>

<ol>
<li> Distributed Representation/Embeddings (feature learning)</br>
<li> Current deep architectures (multiple levels of feature learning)</br>
<li> System 2 deep learning (compose a few concepts at a time). Hint: System 2 is from Daniel Kahneman's work.</br>
</ol>

[ref: system 2 deep learning](https://bdtechtalks.com/2019/12/23/yoshua-bengio-neurips-2019-deep-learning/)


> Each faeture can be discovered without need for seeing exponentially large number of configurations

**Why Multiple Layers**

World is composiitional
Yann LeCun

insert paper Yann LeCun faeture

</br>

Learning multiple levels of abstraction
insert paper for Bengio LeCun 2007

</br>

### Bengio's Neural Probablistic Model, 2003

Generalises to words that are sematically similar (mean the same thing) to training examples.

Basically finds different ways to say the same things?

Gives example of Neural Work Embedding visualiastion




